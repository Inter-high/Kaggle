{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tqdm import tqdm\n",
    "from lightgbm import early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "sample = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['num_sold']\n"
     ]
    }
   ],
   "source": [
    "nan_columns = train.columns[train.isna().any()].tolist() # NaN값을 가진 컬럼 확인\n",
    "print(nan_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "train = train.dropna(subset=['num_sold']) # num_sold 열에서 결측값이 있는 행만 선택적으로 제거\n",
    "nan_columns = train.columns[train.isna().any()].tolist()\n",
    "print(nan_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Holographic Goose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kaggle Tiers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kerneler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kerneler Dark Mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98545</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Premium Sticker Mart</td>\n",
       "      <td>Holographic Goose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98546</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Premium Sticker Mart</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98547</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Premium Sticker Mart</td>\n",
       "      <td>Kaggle Tiers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98548</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Premium Sticker Mart</td>\n",
       "      <td>Kerneler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98549</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Premium Sticker Mart</td>\n",
       "      <td>Kerneler Dark Mode</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98550 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date    country                 store             product\n",
       "0      2017-01-01     Canada     Discount Stickers   Holographic Goose\n",
       "1      2017-01-01     Canada     Discount Stickers              Kaggle\n",
       "2      2017-01-01     Canada     Discount Stickers        Kaggle Tiers\n",
       "3      2017-01-01     Canada     Discount Stickers            Kerneler\n",
       "4      2017-01-01     Canada     Discount Stickers  Kerneler Dark Mode\n",
       "...           ...        ...                   ...                 ...\n",
       "98545  2019-12-31  Singapore  Premium Sticker Mart   Holographic Goose\n",
       "98546  2019-12-31  Singapore  Premium Sticker Mart              Kaggle\n",
       "98547  2019-12-31  Singapore  Premium Sticker Mart        Kaggle Tiers\n",
       "98548  2019-12-31  Singapore  Premium Sticker Mart            Kerneler\n",
       "98549  2019-12-31  Singapore  Premium Sticker Mart  Kerneler Dark Mode\n",
       "\n",
       "[98550 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id 컬럼 삭제\n",
    "train.drop('id', axis=1)\n",
    "test.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['month_name'] = df['date'].dt.month_name()\n",
    "    df['day_of_week'] = df['date'].dt.day_name()\n",
    "    df['week'] = df['date'].dt.isocalendar().week\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12) \n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    df['day_sin'] = np.sin(2 * np.pi * df['day'] / 31)  \n",
    "    df['day_cos'] = np.cos(2 * np.pi * df['day'] / 31)\n",
    "    df['group'] = (df['year'] - 2020) * 48 + df['month'] * 4 + df['day'] // 7\n",
    "    \n",
    "    df.drop('date', axis=1, inplace=True)\n",
    "\n",
    "    df['cos_year'] = np.cos(df['year'] * (2 * np.pi) / 100)\n",
    "    df['sin_year'] = np.sin(df['year'] * (2 * np.pi) / 100)\n",
    "    df['year_lag_1'] = df['year'].shift(1)\n",
    "    df['year_diff'] = df['year'] - df['year_lag_1']\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def ohe_transform(train, test, cat_cols):\n",
    "    ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore') # 예를 들어, 열 color에 값 ['red', 'blue', 'green']이 있다면, red, blue, green 각각에 해당하는 새로운 열이 만들어집니다.\n",
    "\n",
    "    train_ohe = pd.DataFrame(ohe.fit_transform(train[cat_cols]), \n",
    "                                columns=ohe.get_feature_names_out(cat_cols), \n",
    "                                index=train.index)\n",
    "    \n",
    "    test_ohe = pd.DataFrame(ohe.transform(test[cat_cols]), \n",
    "                            columns=ohe.get_feature_names_out(cat_cols), \n",
    "                            index=test.index)\n",
    "    \n",
    "    print(f\"train_ohe: {len(train_ohe.columns)}\")\n",
    "    print(f\"test_ohe: {len(test_ohe.columns)}\")\n",
    "\n",
    "    train = train.drop(columns=cat_cols).reset_index(drop=True)\n",
    "    test = test.drop(columns=cat_cols).reset_index(drop=True)\n",
    "\n",
    "    train = pd.concat([train, train_ohe.reset_index(drop=True)], axis=1)\n",
    "    test = pd.concat([test, test_ohe.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ohe: 33\n",
      "test_ohe: 33\n"
     ]
    }
   ],
   "source": [
    "train = date(df=train)\n",
    "test = date(df=test)\n",
    "\n",
    "cat_c = ['country', 'store', 'product', 'month_name', 'day_of_week']\n",
    "ohe_cols = {'cat_c': cat_c}\n",
    "\n",
    "cat_c = ohe_cols.get('cat_c', [])\n",
    "\n",
    "train, test = ohe_transform(\n",
    "    train=train,\n",
    "    test=test,\n",
    "    cat_cols=cat_c\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = train.drop('num_sold', axis=1) # num_sold 컬럼을 제외한 나머지를 반환\n",
    "y_train_ = train['num_sold']\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log = True\n",
    "n_splits = 5\n",
    "SEED = 114514\n",
    "e_stop = 200\n",
    "early_stop = True\n",
    "gpu = False\n",
    "optuna = False\n",
    "g_col='group'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    return mean_absolute_percentage_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-15 01:38:26,303] A new study created in memory with name: no-name-1bf0c359-1ff6-49a8-9b50-ed2e2dbe5a0f\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b07b978892d43bc819982befa07d487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-15 01:38:43,569] Trial 0 finished with value: 0.04813832373297207 and parameters: {'n_estimators': 782, 'max_depth': 3, 'colsample_bytree': 0.3104180922503826, 'subsample': 0.42728404663044894, 'learning_rate': 0.16840381276654476, 'min_child_samples': 84}. Best is trial 0 with value: 0.04813832373297207.\n",
      "[I 2025-01-15 01:39:03,140] Trial 1 finished with value: 0.05086232418784435 and parameters: {'n_estimators': 652, 'max_depth': 7, 'colsample_bytree': 0.6901407323157852, 'subsample': 0.8597853597755878, 'learning_rate': 0.021448427417877846, 'min_child_samples': 96}. Best is trial 0 with value: 0.04813832373297207.\n",
      "[I 2025-01-15 01:39:22,908] Trial 2 finished with value: 0.046177525762663554 and parameters: {'n_estimators': 729, 'max_depth': 9, 'colsample_bytree': 0.3834726548784321, 'subsample': 0.36812219233164606, 'learning_rate': 0.14973910338099403, 'min_child_samples': 64}. Best is trial 2 with value: 0.046177525762663554.\n",
      "[I 2025-01-15 01:39:42,995] Trial 3 finished with value: 0.05007824446944763 and parameters: {'n_estimators': 564, 'max_depth': 9, 'colsample_bytree': 0.5194545175916455, 'subsample': 0.7585322532664587, 'learning_rate': 0.026490812144344747, 'min_child_samples': 13}. Best is trial 2 with value: 0.046177525762663554.\n",
      "[I 2025-01-15 01:40:01,275] Trial 4 finished with value: 0.10194293418597793 and parameters: {'n_estimators': 553, 'max_depth': 4, 'colsample_bytree': 0.35163498837849066, 'subsample': 0.6774046586067743, 'learning_rate': 0.015176860141878594, 'min_child_samples': 61}. Best is trial 2 with value: 0.046177525762663554.\n",
      "Best trial:\n",
      "  Value: 0.046177525762663554\n",
      "  Params:\n",
      "    n_estimators: 729\n",
      "    max_depth: 9\n",
      "    colsample_bytree: 0.3834726548784321\n",
      "    subsample: 0.36812219233164606\n",
      "    learning_rate: 0.14973910338099403\n",
      "    min_child_samples: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds:  20%|██        | 1/5 [00:01<00:05,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Train MAPE: 0.0409, OOF MAPE: 0.0454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds:  40%|████      | 2/5 [00:02<00:04,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Train MAPE: 0.0409, OOF MAPE: 0.0467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds:  60%|██████    | 3/5 [00:04<00:02,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Train MAPE: 0.0407, OOF MAPE: 0.0466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds:  80%|████████  | 4/5 [00:05<00:01,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Train MAPE: 0.0407, OOF MAPE: 0.0460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 5/5 [00:07<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 - Train MAPE: 0.0407, OOF MAPE: 0.0462\n",
      "Overall Train MAPE: 0.0408\n",
      "Overall OOF MAPE: 0.0462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.3, 1.0),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "        'random_state': SEED,\n",
    "        'device': 'gpu' if gpu else 'cpu'\n",
    "    }\n",
    "\n",
    "    kfold = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    oof_scores = []\n",
    "    reported_steps = set()\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train_, y_train_, groups=X_train_[g_col])):\n",
    "        X_train, X_val = X_train_.iloc[train_idx], X_train_.iloc[val_idx]\n",
    "        y_train, y_val = y_train_.iloc[train_idx], y_train_.iloc[val_idx]\n",
    "\n",
    "        if y_log:\n",
    "            y_train = np.log1p(y_train)\n",
    "            y_val = np.log1p(y_val)\n",
    "\n",
    "        model = lgb.LGBMRegressor(**params, verbose=-1)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            eval_metric=\"l2\",\n",
    "        )\n",
    "\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        if y_log:\n",
    "            y_val_pred = np.expm1(y_val_pred)\n",
    "            y_val = np.expm1(y_val)\n",
    "\n",
    "        for step in range(len(y_val_pred)):\n",
    "            if step not in reported_steps:\n",
    "                trial.report(mape(y_val, y_val_pred), step)\n",
    "                reported_steps.add(step)\n",
    "\n",
    "        oof_scores.append(mape(y_val, y_val_pred))\n",
    "\n",
    "    mean_oof_score = np.mean(oof_scores)\n",
    "    return mean_oof_score\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=5, show_progress_bar=True)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"Best trial:\")\n",
    "best_trial = study.best_trial\n",
    "print(f\"  Value: {best_trial.value}\")\n",
    "print(\"  Params:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# 최적의 파라미터로 모델 학습\n",
    "def train_best_model(params):\n",
    "    kfold = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    train_scores = []\n",
    "    oof_scores = []\n",
    "    all_models = []\n",
    "    oof_predictions = np.zeros(len(y_train_))\n",
    "    test_preds = (\n",
    "        np.zeros((len(X_test), n_splits))\n",
    "    )\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(tqdm(kfold.split(X_train_, y_train_, groups=X_train_[g_col]), desc=\"Training Folds\", total=n_splits)):\n",
    "        X_train, X_val = X_train_.iloc[train_idx], X_train_.iloc[val_idx]\n",
    "        y_train, y_val = y_train_.iloc[train_idx], y_train_.iloc[val_idx]\n",
    "\n",
    "        if y_log:\n",
    "            y_train = np.log1p(y_train)\n",
    "            y_val = np.log1p(y_val)\n",
    "\n",
    "        callbacks = [early_stopping(stopping_rounds=e_stop, verbose=False)] if early_stop else None\n",
    "\n",
    "        device = 'gpu' if gpu else 'cpu'\n",
    "\n",
    "        model = lgb.LGBMRegressor(**params, random_state=SEED, verbose=-1, device=device)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric=None, callbacks=callbacks)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        if y_log:\n",
    "            y_train_pred = np.expm1(y_train_pred)\n",
    "            y_val_pred = np.expm1(y_val_pred)\n",
    "            y_train = np.expm1(y_train)\n",
    "            y_val = np.expm1(y_val)\n",
    "\n",
    "        oof_predictions[val_idx] = y_val_pred\n",
    "\n",
    "        train_scores.append(mape(y_train, y_train_pred))\n",
    "        oof_scores.append(mape(y_val, y_val_pred))\n",
    "\n",
    "        test_preds[:, fold] = model.predict(X_test)\n",
    "\n",
    "        print(f\"Fold {fold + 1} - Train MAPE: {train_scores[-1]:.4f}, OOF MAPE: {oof_scores[-1]:.4f}\")\n",
    "        all_models.append(model)\n",
    "\n",
    "    mean_train_scores = f\"{np.mean(train_scores):.4f}\"\n",
    "    mean_off_scores = f\"{np.mean(oof_scores):.4f}\"\n",
    "\n",
    "    print(f\"Overall Train MAPE: {mean_train_scores}\")\n",
    "    print(f\"Overall OOF MAPE: {mean_off_scores}\")\n",
    "\n",
    "    mean_test_preds = test_preds.mean(axis=1) if X_test is not None else None\n",
    "\n",
    "    if y_log:\n",
    "        mean_test_preds = np.expm1(mean_test_preds)\n",
    "\n",
    "    return {\n",
    "        \"oof_predictions\": oof_predictions,\n",
    "        \"mean_test_preds\": mean_test_preds,\n",
    "        \"all_models\": all_models,\n",
    "        \"mean_train_scores\": mean_train_scores,\n",
    "        \"mean_off_scores\": mean_off_scores\n",
    "    }\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "final_results = train_best_model(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"num_sold\"] = final_results['mean_test_preds']\n",
    "sample.to_csv(f\"submission_{final_results['mean_off_scores']}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
